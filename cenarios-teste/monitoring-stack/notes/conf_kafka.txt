...-------------------------------- Configuração kafka no openNMS --------------------------------

#1º -> Para aceder à karaf shell para configurar o openNMS
ssh -p 8101 admin@localhost

#2º -> Para configurar o event consumer
config:edit org.opennms.features.kafka.consumer.client
config:property-set bootstrap.servers <my-kafka-ip-1:9092,my-kafka-ip-2:9092>
config:property-set eventsTopic quickstart <opennms-kafka-events>
config:update

#2.5º -> Para configurar o event producer

config:edit org.opennms.features.kafka.producer.client
config:property-set bootstrap.servers kafka-broker-ip:9092
config:update

#3º -> Instalar as features
feature:install opennms-kafka-consumer
feature:install opennms-kafka-producer

#4º -> Fazer sync dos alarmes do openNMS para eventos de kafka
opennms:kafka-sync-alarms

#5º -> Ver os logs
log:tail


------------------------------- Aceder à shell do kafka ----------------------------------------

#1º -> Aceder à shell da imagem de kafka
docker exec -it <nome do container de kafka> /bin/bash

#Notas
A imagem spotify/kafka tem o broker numa abaixo de 0.11 e por isso o producer produz warnings que falhou a realizar tarefas do genero "16:18:56.659 WARN [KafkaSendQueueProcessor] Failed to send record to producer: ProducerRecord(topic=alarms, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=[B@5ec38003, value=[B@2b86eebb, timestamp=null).
org.apache.kafka.common.errors.UnsupportedVersionException: Attempting to use idempotence with a broker which does not support the required message format (v2). The broker must be version 0.11 or later"

Antes tanto o consumer como o producer não se conseguiam conectar ao kafka. Era por estar a por localhost inves do ip da maquina onde o container esta a correr no advertised host.


#NOTAS:
Formato dos eventos de kafka nos topicos lidos pelo OpenNMS têm de ter o formato de eventos do OpenNMS


####################################################################################################

config:edit org.opennms.features.kafka.consumer.client
config:property-set bootstrap.servers broker:29092
config:update


config:edit org.opennms.features.kafka.producer.client
config:property-set bootstrap.servers broker:29092
config:update


kafka-topics --bootstrap-server 192.168.1.30:9092 --create --topic quickstart

kafka-console-producer --bootstrap-server 192.168.1.30:9092 --topic quickstart

kafka-console-consumer --bootstrap-server 192.168.1.30:9092 --topic quickstart --from-beginning


######################################## IMPLEMENTAÇÃO ############################################################

-> Configurações no openNMS pela karaf shell:

config:edit org.opennms.features.kafka.consumer.client
config:property-set bootstrap.servers broker:29092
config:property-set eventsTopic opennms-kafka-events
config:update

-> Fazer Producer:

1º - > criar um ficheiro my-event.proto com o formato seguinte de eventos do openNMS

syntax = "proto3";
option java_package = "org.opennms.features.kafka.consumer.events";
option java_outer_classname = "EventsProto";

// The values differ from the standard codes in OpenNMS
// since proto3 enforces us to start at 0
enum Severity {
    INDETERMINATE = 0;
    CLEARED = 1;
    NORMAL = 2;
    WARNING = 3;
    MINOR = 4;
    MAJOR = 5;
    CRITICAL = 6;
}

message EventParameter {
    string name = 1;
    string value = 2;
}

message Event {
    string uei = 1; // required field
    string source = 2; // required field
    Severity severity = 3; // required field
    string host = 4;
    uint32 node_id = 5;
    string ip_address = 6;
    string service_name = 7;
    uint32 if_index = 8;
    string description = 9;
    string dist_poller = 10;
    string log_dest = 11;
    string log_content = 12;
    repeated EventParameter parameter = 13;
}

2º -> Compilar esse ficheiro para gerar um ficheiro python para importar no producer

protoc --python_out=. src/my-event.proto

3º -> importar o ficheiro gerado anteirormnete e construir o evento pretendido, serializar e enviar para o topico


#####################################################################

bundle:classes org.apache.servicemix.bundles.kafka-clients -> org/apache/kafka/common/serialization/ByteArrayDeserializer.class

sudo docker cp horizon:opt/opennms/lib/org.apache.servicemix.bundles.kafka-clients-3.2.0_1.jar ~/Desktop
sudo docker cp horizon:opt/opennms/bin/send-event.pl ~/Desktop
sudo docker cp horizon:opt/opennms/share/xsds/event.xsd ~/Desktop


ver o formato dos eventos
